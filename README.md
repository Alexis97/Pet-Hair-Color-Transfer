# Pet-Hair-Color-Transfer
## Introduction
* Train a CycleGAN to do pet hair color transfer with pet dataset (from ImageNet).
* The CycleGAN structure is from [pytorch-CycleGAN-and-pix2pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix). We made several modification on it to satisfy our transfer task.
* The train dataset is gathered from ImageNet and Google, but it is unaviliable to publish now. 
* Here are some results:
<center>
	<img src="https://github.com/Alexis97/Pet-Hair-Color-Transfer/blob/master/demos/orange2white1.png" height = 200>
	Transfer dog images from hair color of <font color="orange"> orange to <color/white> white
</center>
<center>
	<img src="https://github.com/Alexis97/Pet-Hair-Color-Transfer/blob/master/demos/white2orange1.png" height = 200>
	Transfer dog images from hair color of <color/orange> white to <color/white> orange
</center>
	
## Network Structure
* Here is the schematic diagram of our method:
<center>
	<img src="https://github.com/Alexis97/Pet-Hair-Color-Transfer/blob/master/demos/schematicDiagram.png" height = 400>
	<center>Schematic Diagram of Pet Hair Color Transfer. </center>
</center>

The left column images are real pet images after segmentation which are categorized by hair color into two domains: X and Y . The middle column images are fake images generated by our generators (G1 and G2 ) which are restricted by discriminators (D2 and D1 ) to obtain a similar distribution as real images in the target domains: Y and X. The right column images are reconstructed images generated by G2 and G1 back to the original domains: X and Y . The reconstructed images are encouraged to be as similar as possible with real images by reconstruction loss.
